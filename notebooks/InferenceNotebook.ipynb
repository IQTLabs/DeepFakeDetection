{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook for DFDC \n",
    "Short notebook to run inference on Deep Fake Detection Challenge test set in submission\n",
    "### Imports\n",
    "Seperated in blocks:\n",
    "- Python imports\n",
    "- Pytorch/torchvision imports\n",
    "- User imports**\n",
    "\n",
    "** Note: As well as our user submitted code, we are rllying on [facenet-pytorch](https://github.com/timesler/facenet-pytorch) for the preprocessing stage to isolate people's faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "import dfdet as dfd\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "Set the device for processing (should be gpu for this analysis) and whether or not to run the preprocessing stage.  This second switch is mostly there for debugging the second stage after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "preprocess = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index data\n",
    "Index the test data and return it in data-frame compatible with our defined data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../deepfake-detection'\n",
    "def index_test_dir(test_path=''):\n",
    "    ''' Index files and create data frame\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_path : str\n",
    "        Path to directory with test files\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame for preprocessing\n",
    "    '''\n",
    "    path, dirs, files = next(os.walk('{}/test_videos'.format(test_path)))\n",
    "    df = pd.DataFrame(files, columns=['File'])\n",
    "    df['split'] = 'test_videos'\n",
    "    df['label'] = -1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Preprocessing stage.  Feed to the files to face-net pytorch to isolate faces and save the desired frames to a local directory \"temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    df = index_test_dir(test_path)\n",
    "    with open('../config_files/preprocess.yaml') as f:\n",
    "        config = yaml.load(f)\n",
    "    mt = config['mtcnn']\n",
    "    mtcnn = MTCNN(\n",
    "        image_size=mt['image_size'], margin=mt['margin'],\n",
    "        min_face_size=mt['min_face_size'], thresholds=mt['thresholds'],\n",
    "        factor=mt['factor'], post_process=mt['post_process'],\n",
    "        device=device\n",
    "    )\n",
    "    faces_df = dfd.preprocess_df(df=df, mtcnn=mtcnn, path=test_path, \n",
    "                                 outpath='./temp', n_seconds=6, debug=False)\n",
    "    faces_df.to_csv('./temp/faces_metadata.csv')\n",
    "    del mtcnn, df\n",
    "else:\n",
    "    faces_df = pd.read_csv('./temp/faces_metadata.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-indexing\n",
    "Re-index the dataframe to allow the DataLoader to reference the file names.  Not needed but added safegaurd for correct submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_df['label'] = faces_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Fake Detector\n",
    "Create deep fake detector model and load the pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model loss: 0.3598859710824972\n"
     ]
    }
   ],
   "source": [
    "model = dfd.ConvLSTM(num_classes=1, attention=True, encoder='ResNet').to(device)\n",
    "chpt = torch.load('../checkpoints/best_model.pth.tar')\n",
    "model.load_state_dict(chpt['model'])\n",
    "print(chpt['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Create dataset and dataloader using the correct transformations for input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "batch_size = 16\n",
    "testset = dfd.DFDC_Dataset(df=faces_df, transform=transform, path='./temp')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Inference step to produce predictions for the test set and return a dataframe with (File, probability) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfdc_evaluation(df=None, model=None, dataloader=None):\n",
    "    ''' Evaluate model on dataset\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame associated to pre-processed data\n",
    "    model : torch.Module\n",
    "        Pytorch model for inference\n",
    "    dataloader : torch.utils.data.DataLoader\n",
    "        Data-loader for pre-processed data\n",
    "    Returns\n",
    "    -------\n",
    "    probabilities : pd.DataFrame\n",
    "        DataFrame with (filename, probaility) pairs\n",
    "    '''\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    probabilities = []\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        frames, lbls = batch\n",
    "        frames = frames.to(device)\n",
    "        with torch.no_grad():\n",
    "            model.lstm.reset_hidden_state()\n",
    "            predictions = model(frames)\n",
    "        for idx in range(predictions.shape[0]):\n",
    "            probabilities.append(\n",
    "                {'File' : df['File'][lbls[idx].item()], 'Probability': predictions[idx].cpu().item()}\n",
    "            )\n",
    "    return pd.DataFrame(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = dfdc_evaluation(df=faces_df, model=model, dataloader=testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save\n",
    "Create predictions csv for submission to competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-780cd6eac7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3224\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3225\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3226\u001b[0;31m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3227\u001b[0m         )\n\u001b[1;32m   3228\u001b[0m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.3/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, path_or_buf, sep, na_rep, float_format, cols, header, index, index_label, mode, encoding, compression, quoting, line_terminator, chunksize, quotechar, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 )\n\u001b[1;32m    111\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "probabilities.to_csv('submission.csv', index=False, columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
